{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# I have trained the Resnet Model from scratch\n# I also loaded the best model I have on the resnet18.pt file, which goes up to 96.24% on test data and 100% on training data\n\nfrom __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\ninput_size = (224,224)\nbatch_size = 32\n#from __future__ import print_function, division\n#cudnn.benchmark = True\nplt.ion()   # interactive mode\ncriterion = nn.CrossEntropyLoss()\n# Data Transformations\n\ndata_dir = '../input/vgg-data/z'\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.7043, 0.6402, 0.5553],[0.3503, 0.3684, 0.4062])\n        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.7043, 0.6402, 0.5553],[0.3503, 0.3684, 0.4062])\n        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# Create training and validation datasets\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n# Create training and validation dataloaders\nprint(image_datasets['train'][0][0].shape)\ndataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nclass_names = image_datasets['train'].classes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-13T22:18:59.655338Z","iopub.execute_input":"2022-07-13T22:18:59.656233Z","iopub.status.idle":"2022-07-13T22:18:59.856836Z","shell.execute_reply.started":"2022-07-13T22:18:59.656165Z","shell.execute_reply":"2022-07-13T22:18:59.855958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mean_and_std(dataloader):\n    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n    for data, _ in dataloader:\n        # Mean over batch, height and width, but not over the channels\n        channels_sum += torch.mean(data, dim=[0,2,3])\n        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n        num_batches += 1\n    \n    mean = channels_sum / num_batches\n\n    # std = sqrt(E[X^2] - (E[X])^2)\n    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n\n    return mean, std","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:19:03.062626Z","iopub.execute_input":"2022-07-13T22:19:03.063316Z","iopub.status.idle":"2022-07-13T22:19:03.069874Z","shell.execute_reply.started":"2022-07-13T22:19:03.063274Z","shell.execute_reply":"2022-07-13T22:19:03.069083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean, std = get_mean_and_std(dataloaders_dict['train'])","metadata":{"execution":{"iopub.status.busy":"2022-07-13T02:31:05.919887Z","iopub.execute_input":"2022-07-13T02:31:05.920546Z","iopub.status.idle":"2022-07-13T02:31:25.558218Z","shell.execute_reply.started":"2022-07-13T02:31:05.920505Z","shell.execute_reply":"2022-07-13T02:31:25.557021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-13T02:31:30.557963Z","iopub.execute_input":"2022-07-13T02:31:30.559007Z","iopub.status.idle":"2022-07-13T02:31:30.566418Z","shell.execute_reply.started":"2022-07-13T02:31:30.558962Z","shell.execute_reply":"2022-07-13T02:31:30.565263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-13T01:08:12.665332Z","iopub.execute_input":"2022-07-13T01:08:12.665673Z","iopub.status.idle":"2022-07-13T01:08:12.672223Z","shell.execute_reply.started":"2022-07-13T01:08:12.665643Z","shell.execute_reply":"2022-07-13T01:08:12.671208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimage_datasets['train'][0][0].shape\nplt.imshow(image_datasets['train'][0][0].numpy().transpose(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T02:22:16.658261Z","iopub.execute_input":"2022-07-12T02:22:16.658939Z","iopub.status.idle":"2022-07-12T02:22:16.905672Z","shell.execute_reply.started":"2022-07-12T02:22:16.658897Z","shell.execute_reply":"2022-07-12T02:22:16.904643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport copy\nimg = copy.deepcopy(image_datasets['train'][0][0].numpy().transpose(1,2,0))\nplt.imshow(img)\ndef set_pixel(x, i, j, value=0):\n    x[0][i][j] = value\n    x[1][i][j] = value\n    x[2][i][j] = value\n    return x\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T03:25:35.822010Z","iopub.execute_input":"2022-07-12T03:25:35.822651Z","iopub.status.idle":"2022-07-12T03:25:36.070676Z","shell.execute_reply.started":"2022-07-12T03:25:35.822609Z","shell.execute_reply":"2022-07-12T03:25:36.069660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.imshow(set_pixel(img, 100,150))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T02:30:58.940811Z","iopub.execute_input":"2022-07-12T02:30:58.941735Z","iopub.status.idle":"2022-07-12T02:30:58.962591Z","shell.execute_reply.started":"2022-07-12T02:30:58.941690Z","shell.execute_reply":"2022-07-12T02:30:58.961222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = image_datasets['train'][0][0]\ninputs.to(\"cuda\")\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T02:33:25.512611Z","iopub.execute_input":"2022-07-12T02:33:25.514117Z","iopub.status.idle":"2022-07-12T02:33:25.567910Z","shell.execute_reply.started":"2022-07-12T02:33:25.514065Z","shell.execute_reply":"2022-07-12T02:33:25.566858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = next(iter(dataloaders_dict['train']))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T03:25:41.257883Z","iopub.execute_input":"2022-07-12T03:25:41.258974Z","iopub.status.idle":"2022-07-12T03:25:44.094868Z","shell.execute_reply.started":"2022-07-12T03:25:41.258926Z","shell.execute_reply":"2022-07-12T03:25:44.093210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = img.to(\"cuda\")\nimport random\n\nfor pic in img:\n    random_x = int(random.random()*224)\n    random_y = int(random.random()*224)\n    #print(pic)\n    pic = set_pixel(pic, random_x, random_y)\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T03:41:47.870024Z","iopub.execute_input":"2022-07-12T03:41:47.870406Z","iopub.status.idle":"2022-07-12T03:41:47.879565Z","shell.execute_reply.started":"2022-07-12T03:41:47.870374Z","shell.execute_reply":"2022-07-12T03:41:47.878586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = img.to(\"cpu\")\nplt.imshow(img[5].numpy().transpose(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T03:29:35.060993Z","iopub.execute_input":"2022-07-12T03:29:35.061425Z","iopub.status.idle":"2022-07-12T03:29:35.276821Z","shell.execute_reply.started":"2022-07-12T03:29:35.061389Z","shell.execute_reply":"2022-07-12T03:29:35.275742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = img.to(\"cuda\")\noutputs = model(img)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T03:42:03.729152Z","iopub.execute_input":"2022-07-12T03:42:03.729824Z","iopub.status.idle":"2022-07-12T03:42:03.745949Z","shell.execute_reply.started":"2022-07-12T03:42:03.729785Z","shell.execute_reply":"2022-07-12T03:42:03.744733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_,preds = np.max(outputs, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T03:42:05.587439Z","iopub.execute_input":"2022-07-12T03:42:05.587817Z","iopub.status.idle":"2022-07-12T03:42:05.615743Z","shell.execute_reply.started":"2022-07-12T03:42:05.587785Z","shell.execute_reply":"2022-07-12T03:42:05.614117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18(pretrained = True)\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features, 18)\nmodel.load_state_dict(torch.load('../input/resnet18/resnet18.pt'))\n#model = models.vgg11_bn(pretrained=True)\n#set_parameter_requires_grad(model, feature_extract)\n#num_ftrs = model.classifier[6].in_features\n#model.classifier[6] = nn.Linear(num_ftrs,18)\nmodel.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:19:15.016391Z","iopub.execute_input":"2022-07-13T22:19:15.017083Z","iopub.status.idle":"2022-07-13T22:19:16.083000Z","shell.execute_reply.started":"2022-07-13T22:19:15.017034Z","shell.execute_reply":"2022-07-13T22:19:16.081719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tests = []\ny_tests = []\n#x_trains = np.array(x_trains)\nfor x,y in image_datasets['val']:\n    x_tests.append(x.numpy())\n    y_tests.append(y)\ny_trains = []\nx_trains = []\n#x_trains = np.array(x_trains)\n#for x,y in image_datasets['train']:\n#    x_trains.append(x.numpy())\n#    y_trains.append(y)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:19:19.774542Z","iopub.execute_input":"2022-07-13T22:19:19.774953Z","iopub.status.idle":"2022-07-13T22:19:28.480720Z","shell.execute_reply.started":"2022-07-13T22:19:19.774920Z","shell.execute_reply":"2022-07-13T22:19:28.479618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tests = np.array(x_tests)\ny_tests = np.array(y_tests)\n#x_trains = np.array(x_trains)\n#y_trains = np.array(y_trains)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:19:36.497469Z","iopub.execute_input":"2022-07-13T22:19:36.497898Z","iopub.status.idle":"2022-07-13T22:19:36.641678Z","shell.execute_reply.started":"2022-07-13T22:19:36.497864Z","shell.execute_reply":"2022-07-13T22:19:36.640540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_hot(a, num_classes):\n  return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n#y_trains = one_hot(y_trains,18)\ny_tests = one_hot(y_tests,18)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:19:38.838235Z","iopub.execute_input":"2022-07-13T22:19:38.839068Z","iopub.status.idle":"2022-07-13T22:19:38.844124Z","shell.execute_reply.started":"2022-07-13T22:19:38.839030Z","shell.execute_reply":"2022-07-13T22:19:38.843220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install adversarial-robustness-toolbox","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:19:41.398473Z","iopub.execute_input":"2022-07-13T22:19:41.399417Z","iopub.status.idle":"2022-07-13T22:19:52.865733Z","shell.execute_reply.started":"2022-07-13T22:19:41.399372Z","shell.execute_reply":"2022-07-13T22:19:52.864136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.trainer import AdversarialTrainer\nfrom art.attacks.evasion import FastGradientMethod\nfrom art.attacks.evasion import ProjectedGradientDescent\nimport torch.optim as optim\nfrom art.estimators.classification import PyTorchClassifier","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:20:38.147560Z","iopub.execute_input":"2022-07-13T22:20:38.147982Z","iopub.status.idle":"2022-07-13T22:20:38.154692Z","shell.execute_reply.started":"2022-07-13T22:20:38.147948Z","shell.execute_reply":"2022-07-13T22:20:38.153796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\ncriterion = nn.CrossEntropyLoss()\n#from art.defences.postprocessor import Rounded\n#post =Rounded()\nclassy = PyTorchClassifier(\n    model=model,\n    loss=criterion,\n    #optimizer = optimizer,\n    input_shape = (3,224,224),\n    nb_classes =18,\n    clip_values = (0,1)\n    #postprocessing_defences = post\n    \n)\n#model.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:21:08.746638Z","iopub.execute_input":"2022-07-13T22:21:08.747033Z","iopub.status.idle":"2022-07-13T22:21:08.756864Z","shell.execute_reply.started":"2022-07-13T22:21:08.747002Z","shell.execute_reply":"2022-07-13T22:21:08.755647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import SpatialSmoothing\nfrom art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import FeatureSqueezing\nfrom art.defences.preprocessor import ThermometerEncoding\nfrom art.defences.preprocessor import GaussianAugmentation\nfrom art.defences.preprocessor import LabelSmoothing\nfrom art.defences.preprocessor import JpegCompression\nfrom art.defences.preprocessor import JpegCompression","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:20:49.772721Z","iopub.execute_input":"2022-07-13T22:20:49.773776Z","iopub.status.idle":"2022-07-13T22:20:49.779998Z","shell.execute_reply.started":"2022-07-13T22:20:49.773734Z","shell.execute_reply":"2022-07-13T22:20:49.779167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"pgd = ProjectedGradientDescent(\n    estimator=classy\n    \n)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:20:53.561729Z","iopub.execute_input":"2022-07-13T22:20:53.564543Z","iopub.status.idle":"2022-07-13T22:20:53.570231Z","shell.execute_reply.started":"2022-07-13T22:20:53.564478Z","shell.execute_reply":"2022-07-13T22:20:53.568731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images_pgd = pgd.generate(x=x_tests, verbose = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:26:53.347243Z","iopub.execute_input":"2022-07-13T22:26:53.347702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-13T13:12:58.565553Z","iopub.execute_input":"2022-07-13T13:12:58.566221Z","iopub.status.idle":"2022-07-13T13:12:58.572461Z","shell.execute_reply.started":"2022-07-13T13:12:58.566169Z","shell.execute_reply":"2022-07-13T13:12:58.571239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#score_clean = vulnerable_classifier._model.eval(x=x_tests, y=y_tests)\n#score_fgm = vulnerable_classifier._model.eval(x=test_images_fgm, y=y_tests)\n\npredictions = classy.predict(x_tests)\nprint(predictions)\nprint(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"Clean accuracy:\", accuracy)\n\npredictions = classy.predict(test_images_pgd)\nprint(predictions)\nprint(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"Adversarial PGD accuracy:\", accuracy)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:19:32.271479Z","iopub.execute_input":"2022-07-13T19:19:32.272149Z","iopub.status.idle":"2022-07-13T19:19:33.467281Z","shell.execute_reply.started":"2022-07-13T19:19:32.272112Z","shell.execute_reply":"2022-07-13T19:19:33.466291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classy2)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T05:05:35.409862Z","iopub.execute_input":"2022-07-13T05:05:35.410914Z","iopub.status.idle":"2022-07-13T05:05:35.501009Z","shell.execute_reply.started":"2022-07-13T05:05:35.410802Z","shell.execute_reply":"2022-07-13T05:05:35.499776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\nfrom art.attacks.poisoning import PoisoningAttackBackdoor\nfrom art.attacks.poisoning.perturbations import add_pattern_bd\nfrom art.defences.detector.poison import ActivationDefence\nfrom art.estimators.classification import KerasClassifier\nfrom art.utils import load_dataset, to_categorical\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pprint\nimport json","metadata":{"execution":{"iopub.status.busy":"2022-07-13T02:45:06.968927Z","iopub.execute_input":"2022-07-13T02:45:06.969981Z","iopub.status.idle":"2022-07-13T02:45:08.135621Z","shell.execute_reply.started":"2022-07-13T02:45:06.969920Z","shell.execute_reply":"2022-07-13T02:45:08.134595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.compat.v1.disable_eager_execution()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:53:47.66028Z","iopub.execute_input":"2022-07-07T00:53:47.661274Z","iopub.status.idle":"2022-07-07T00:53:47.666704Z","shell.execute_reply.started":"2022-07-07T00:53:47.661235Z","shell.execute_reply":"2022-07-07T00:53:47.665606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import SpatialSmoothing\nfrom art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import FeatureSqueezing\nfrom art.defences.preprocessor import ThermometerEncoding\nfrom art.defences.preprocessor import GaussianAugmentation\nfrom art.defences.preprocessor import LabelSmoothing\nfrom art.defences.preprocessor import JpegCompression\nfrom art.defences.preprocessor import JpegCompression","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:44:48.773934Z","iopub.execute_input":"2022-07-13T18:44:48.774320Z","iopub.status.idle":"2022-07-13T18:44:48.781032Z","shell.execute_reply.started":"2022-07-13T18:44:48.774289Z","shell.execute_reply":"2022-07-13T18:44:48.780031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defense3 = TotalVarMin(norm = 1, solver = 'CG', max_iter = 10, verbose = True) \ntest_images_pgd_cleanestest = defense3(test_images_pgd_cleanest)[0]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:53:12.252493Z","iopub.execute_input":"2022-07-13T18:53:12.252889Z","iopub.status.idle":"2022-07-13T19:09:06.151993Z","shell.execute_reply.started":"2022-07-13T18:53:12.252842Z","shell.execute_reply":"2022-07-13T19:09:06.151061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defense = GaussianAugmentation(clip_values = (0,1))\n\n#defense2 = JpegCompression(clip_values = (0,1)) \ndefense3 = TotalVarMin(norm = 1, solver = 'CG') \ndefense4 = SpatialSmoothing()\n#test_images_pgd_clean = defense3(test_images_pgd)[0]\ntest_images_pgd_cleaner = defense4(test_images_pgd)[0]\ntest_images_pgd_cleanest = defense(test_images_pgd_cleaner)[0]\n#test_images_pgd_cleanestest = defense2(test_images_pgd_cleanest)[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-13T18:50:58.866927Z","iopub.execute_input":"2022-07-13T18:50:58.867365Z","iopub.status.idle":"2022-07-13T18:51:10.020749Z","shell.execute_reply.started":"2022-07-13T18:50:58.867327Z","shell.execute_reply":"2022-07-13T18:51:10.019701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defense2 = ThermometerEncoding(clip_values = (0,1))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T04:44:29.829578Z","iopub.execute_input":"2022-07-13T04:44:29.830044Z","iopub.status.idle":"2022-07-13T04:44:29.835609Z","shell.execute_reply.started":"2022-07-13T04:44:29.830008Z","shell.execute_reply":"2022-07-13T04:44:29.834613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images_pgd_cleanestest = defense2(test_images_pgd_cleanest)[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-13T04:44:39.692268Z","iopub.execute_input":"2022-07-13T04:44:39.692645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defense3 = SpatialSmoothing() \n\ntest_images_pgd_cleanest = defense3(test_images_pgd_cleaner)[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T13:38:15.830677Z","iopub.execute_input":"2022-07-11T13:38:15.831070Z","iopub.status.idle":"2022-07-11T13:38:35.788443Z","shell.execute_reply.started":"2022-07-11T13:38:15.831038Z","shell.execute_reply":"2022-07-11T13:38:35.787367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images_pgd_cleanestest= defense4(test_images_pgd_cleanest)[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-11T13:38:40.870742Z","iopub.execute_input":"2022-07-11T13:38:40.871132Z","iopub.status.idle":"2022-07-11T14:08:59.636956Z","shell.execute_reply.started":"2022-07-11T13:38:40.871098Z","shell.execute_reply":"2022-07-11T14:08:59.635631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import GaussianAugmentation\nfrom art.defences.preprocessor import LabelSmoothing\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:28:03.497558Z","iopub.execute_input":"2022-07-07T19:28:03.498077Z","iopub.status.idle":"2022-07-07T19:28:03.502636Z","shell.execute_reply.started":"2022-07-07T19:28:03.498039Z","shell.execute_reply":"2022-07-07T19:28:03.50147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defense2 = SpatialSmoothing()\ntest_images_pgd_cleaner = defense2(test_images_pgd_cleaned)[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:28:04.638174Z","iopub.execute_input":"2022-07-07T19:28:04.638876Z","iopub.status.idle":"2022-07-07T19:28:10.013211Z","shell.execute_reply.started":"2022-07-07T19:28:04.638819Z","shell.execute_reply":"2022-07-07T19:28:10.012129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndefense3 = GaussianAugmentation(apply_predict = True, ratio= 2, clip_values= (0,1))\ntest_images_pgd_cleanest = defense3(test_images_pgd_cleaner)[0]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:28:18.03425Z","iopub.execute_input":"2022-07-07T19:28:18.034725Z","iopub.status.idle":"2022-07-07T19:28:26.369742Z","shell.execute_reply.started":"2022-07-07T19:28:18.034684Z","shell.execute_reply":"2022-07-07T19:28:26.36859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import JpegCompression\ndefense4 = JpegCompression(clip_values=(0,1), apply_predict = True)\ntest_images_pgd_cleanestest = defense4(test_images_pgd_cleanest)[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:28:27.813189Z","iopub.execute_input":"2022-07-07T19:28:27.813995Z","iopub.status.idle":"2022-07-07T19:29:49.933217Z","shell.execute_reply.started":"2022-07-07T19:28:27.813954Z","shell.execute_reply":"2022-07-07T19:29:49.932102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images_pgd_cleanestest","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:45:51.504527Z","iopub.execute_input":"2022-07-07T18:45:51.50494Z","iopub.status.idle":"2022-07-07T18:45:51.522708Z","shell.execute_reply.started":"2022-07-07T18:45:51.504899Z","shell.execute_reply":"2022-07-07T18:45:51.521819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy\n\nnumpy.save('pgd_cleaned.txt', test_images_pgd_cleaned)\nnumpy.save('pgd.txt', test_images_pgd)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T17:54:10.293248Z","iopub.execute_input":"2022-07-07T17:54:10.294073Z","iopub.status.idle":"2022-07-07T17:54:10.834924Z","shell.execute_reply.started":"2022-07-07T17:54:10.294035Z","shell.execute_reply":"2022-07-07T17:54:10.826682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-07-07T17:52:37.053225Z","iopub.execute_input":"2022-07-07T17:52:37.054176Z","iopub.status.idle":"2022-07-07T17:52:37.797261Z","shell.execute_reply.started":"2022-07-07T17:52:37.054131Z","shell.execute_reply":"2022-07-07T17:52:37.796187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = classy.predict(test_images_pgd)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"Adversarial accuracy:\", accuracy)\n\n\npredictions = classy.predict(test_images_pgd_cleaner)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 1 Adversarial Defense accuracy:\", accuracy)\n\npredictions = classy.predict(test_images_pgd_cleanest)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 2 Adversarial Defenses accuracy:\", accuracy)\n\npredictions = classy.predict(test_images_pgd_cleanest)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 3 Adversarial Defenses accuracy:\", accuracy)\n\npredictions = classy.predict(test_images_pgd_cleanestest)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 3 Adversarial Defenses accuracy:\", accuracy)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-13T19:14:20.331595Z","iopub.execute_input":"2022-07-13T19:14:20.331942Z","iopub.status.idle":"2022-07-13T19:14:24.713106Z","shell.execute_reply.started":"2022-07-13T19:14:20.331913Z","shell.execute_reply":"2022-07-13T19:14:24.712074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18(pretrained = True)\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features, 18)\nmodel.load_state_dict(torch.load('../input/resnet18/resnet18.pt'))\nmodel.to('cuda')\nclassifier = PyTorchClassifier(model = model, loss = criterion, input_shape = (3,224,224),nb_classes = 18)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T02:44:46.056288Z","iopub.execute_input":"2022-07-07T02:44:46.057392Z","iopub.status.idle":"2022-07-07T02:44:46.3349Z","shell.execute_reply.started":"2022-07-07T02:44:46.057319Z","shell.execute_reply":"2022-07-07T02:44:46.33385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adversarial accuracy: 0.020876826722338204\nWith 1 Adversarial Defense accuracy: 0.4154488517745303\nWith 2 Adversarial Defenses accuracy: 0.6910229645093946\nWith 3 Adversarial Defenses accuracy: 0.8517745302713987\n\ndata = {'':20, 'C++':15, 'Java':30,\n        'Python':35}\ncourses = list(data.keys())\nvalues = list(data.values())\n  \nfig = plt.figure(figsize = (10, 5))\n \n# creating the bar plot\nplt.bar(courses, values, color ='maroon',\n        width = 0.4)\n \nplt.xlabel(\"Courses offered\")\nplt.ylabel(\"No. of students enrolled\")\nplt.title(\"Students enrolled in different courses\")\nplt.show()","metadata":{}},{"cell_type":"code","source":"img, label = next(iter(dataloaders_dict['val']))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T23:16:04.354745Z","iopub.execute_input":"2022-07-10T23:16:04.355494Z","iopub.status.idle":"2022-07-10T23:16:06.990963Z","shell.execute_reply.started":"2022-07-10T23:16:04.355455Z","shell.execute_reply":"2022-07-10T23:16:06.989708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = classy.predict(test_images_pgd)\noutput2 = classy.predict(test_images_pgd_cleanest)\n#print(output)\npreds = np.argmax(output,axis = 1)\nprint(preds)\npreds = np.argmax(y_tests,axis = 1)\n\nprint(preds)\npreds = np.argmax(output2,axis = 1)[0:478]\nprint(preds)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T23:24:26.642232Z","iopub.execute_input":"2022-07-10T23:24:26.642571Z","iopub.status.idle":"2022-07-10T23:24:28.811492Z","shell.execute_reply.started":"2022-07-10T23:24:26.642541Z","shell.execute_reply":"2022-07-10T23:24:28.809362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7, 5)) \nimport matplotlib.pyplot as plt\nacc = [0.67223382045929018*100,.8288100208768268*100, 0.8622129436325678*100, ]\nmodel = [\"Original\", \"Spatial Smoothing\",\"Total Variance Minimization\"]\nplt.title('Accuracy for Different Defences against FGSM (eps = .2)')\nplt.xlabel('Defense')\nplt.ylabel('Accuracy')\nplt.bar(model, acc)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:48:05.19956Z","iopub.execute_input":"2022-07-07T19:48:05.200101Z","iopub.status.idle":"2022-07-07T19:48:05.353383Z","shell.execute_reply.started":"2022-07-07T19:48:05.200063Z","shell.execute_reply":"2022-07-07T19:48:05.352317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(7, 5)) \nimport matplotlib.pyplot as plt\nacc = [0.020876826722338204*100,0.4154488517745303*100, 0.6910229645093946*100, 0.8517745302713987*100,0.8434237995824635*100]\nmodel = [\"Original\", \"1\",\"1+2\", \"1+2+3\", \"1+2+3+4\"]\nplt.title('Accuracy for Different Defences against PGD')\nplt.xlabel('Defense')\nplt.ylabel('Accuracy')\nplt.bar(model, acc)\nplt.show()\nplt.legend(\"hi\")","metadata":{"execution":{"iopub.status.busy":"2022-07-07T19:44:26.45895Z","iopub.execute_input":"2022-07-07T19:44:26.459651Z","iopub.status.idle":"2022-07-07T19:44:26.795814Z","shell.execute_reply.started":"2022-07-07T19:44:26.459611Z","shell.execute_reply":"2022-07-07T19:44:26.794858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiered = PyTorchClassifier(model = model, loss = criterion, input_shape =(3,224,224), nb_classes = 18)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-07T02:12:22.830937Z","iopub.execute_input":"2022-07-07T02:12:22.831316Z","iopub.status.idle":"2022-07-07T02:12:22.841281Z","shell.execute_reply.started":"2022-07-07T02:12:22.831283Z","shell.execute_reply":"2022-07-07T02:12:22.840276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_figure_axes(\n    nrows, \n    ncols, \n    figsize\n    ):\n    # Creating a figure and axes\n    fig, axes = plt.subplots(\n        nrows=nrows, \n        ncols=ncols, \n        figsize=figsize\n        )\n\n    # Returning the figure and axes\n    return fig, axes","metadata":{"execution":{"iopub.status.busy":"2022-07-07T17:54:46.95551Z","iopub.execute_input":"2022-07-07T17:54:46.955914Z","iopub.status.idle":"2022-07-07T17:54:46.962348Z","shell.execute_reply.started":"2022-07-07T17:54:46.955872Z","shell.execute_reply":"2022-07-07T17:54:46.961103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nrows, ncols = 5, 5\n\n# Creating a plot figure and axes for the samples\n\nfig, axes = create_figure_axes(\n    nrows=nrows, \n    ncols=ncols, \n    figsize=(20, 25)\n    )\n\n# Defining a counting variable\ncounter = 0\n\n# Indicating the purpose of each column\naxes[0, 0].set_title(\n        label=\"PDG images\", \n        pad=25\n        )\naxes[0, 1].set_title(\n        label=\"Clean images\", \n        pad=25\n        )\naxes[0, 2].set_title(\n        label=\"Total Var Min\", \n        pad=25\n        )\naxes[0, 3].set_title(\n        label=\"Total Var Min + Spatial Smooth.\", \n        pad=25\n        )\naxes[0, 4].set_title(\n        label=\"Left Defenses+Gauss.Aug.\", \n        pad=25\n        )\n\n# Iterating over the axis rows in our figure\nfor i in range(nrows):    \n        # Plotting the adversarial image,\n        # turning off axis ticks,\n        # and setting the axis title\n        axes[i, 0].imshow(test_images_pgd[counter].transpose(1,2,0))        \n        axes[i, 0].set_xticks(ticks=[])\n        axes[i, 0].set_yticks(ticks=[])\n        \n\n        # Plotting the cleaned image,\n        # turning off axis ticks,\n        # and setting the axis title\n        axes[i, 1].imshow(x_tests[counter].transpose(1,2,0))\n        axes[i, 1].set_xticks(ticks=[])\n        axes[i, 1].set_yticks(ticks=[])\n        \n        axes[i, 2].imshow(test_images_pgd_cleaned[counter].transpose(1,2,0))\n        axes[i, 2].set_xticks(ticks=[])\n        axes[i, 2].set_yticks(ticks=[])\n        \n        axes[i, 3].imshow(test_images_pgd_cleaner[counter].transpose(1,2,0))\n        axes[i, 3].set_xticks(ticks=[])\n        axes[i, 3].set_yticks(ticks=[])\n        \n        axes[i, 4].imshow(test_images_pgd_cleanest[counter].transpose(1,2,0))\n        axes[i, 4].set_xticks(ticks=[])\n        axes[i, 4].set_yticks(ticks=[])\n\n\n\n        \n        # Incrementing counter value\n        counter += 1\n\n# Showing the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T18:11:24.545562Z","iopub.execute_input":"2022-07-07T18:11:24.545935Z","iopub.status.idle":"2022-07-07T18:11:26.072567Z","shell.execute_reply.started":"2022-07-07T18:11:24.545902Z","shell.execute_reply":"2022-07-07T18:11:26.071756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(\n    images=x_trains, \n    labels=y_trains,\n    plot_label=\"Label\",\n    is_categorical=True,\n    nrows=2,\n    ncols=5,\n    figsize=(25, 10))","metadata":{"execution":{"iopub.status.busy":"2022-07-07T01:28:30.951012Z","iopub.execute_input":"2022-07-07T01:28:30.951535Z","iopub.status.idle":"2022-07-07T01:28:30.97997Z","shell.execute_reply.started":"2022-07-07T01:28:30.951498Z","shell.execute_reply":"2022-07-07T01:28:30.978651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.efficientnet_b7(pretrained=True)\n#model_ft.classifier[1].out_features = num_classes\nnum_ftrs = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_ftrs, 18)\nmodel.load_state_dict(torch.load('../input/95-efficientnet/95-efficientnet.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:33:49.936064Z","iopub.execute_input":"2022-07-08T16:33:49.937221Z","iopub.status.idle":"2022-07-08T16:33:52.507443Z","shell.execute_reply.started":"2022-07-08T16:33:49.937174Z","shell.execute_reply":"2022-07-08T16:33:52.504382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.classifier[1] = nn.Conv2d(512, 18, kernel_size=(1,1), stride=(1,1))\nmodel.num_classes = 18\nmodel.eval()\nmodel.load_state_dict(torch.load('../input/95squeezenet/95-squeezenet.pth'))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:32:55.539706Z","iopub.execute_input":"2022-07-08T16:32:55.54024Z","iopub.status.idle":"2022-07-08T16:32:55.631782Z","shell.execute_reply.started":"2022-07-08T16:32:55.540194Z","shell.execute_reply":"2022-07-08T16:32:55.628937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes =18\nimport torch.nn as nn\nimport torch\ndef set_parameter_requires_grad(model, feature_extracting = True):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False\n\nset_parameter_requires_grad(model, True)\nmodel.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\nmodel.num_classes = 18\nmodel.load_state_dict(torch.load('../input/95squeezenet/95-squeezenet.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:32:27.583977Z","iopub.execute_input":"2022-07-08T16:32:27.584689Z","iopub.status.idle":"2022-07-08T16:32:27.691937Z","shell.execute_reply.started":"2022-07-08T16:32:27.584656Z","shell.execute_reply":"2022-07-08T16:32:27.689158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pgd_squeezenet = ProjectedGradientDescent(\n    estimator=classy, \n    \n    \n)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:17:13.1197Z","iopub.execute_input":"2022-07-08T16:17:13.120156Z","iopub.status.idle":"2022-07-08T16:17:13.126261Z","shell.execute_reply.started":"2022-07-08T16:17:13.120113Z","shell.execute_reply":"2022-07-08T16:17:13.124988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images_pgd_sqnet = pgd_squeezenet.generate(x=x_tests)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T15:53:08.848764Z","iopub.execute_input":"2022-07-08T15:53:08.849173Z","iopub.status.idle":"2022-07-08T15:54:07.074785Z","shell.execute_reply.started":"2022-07-08T15:53:08.849144Z","shell.execute_reply":"2022-07-08T15:54:07.07359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import SpatialSmoothing\nfrom art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import FeatureSqueezing\nfrom art.defences.preprocessor import ThermometerEncoding\n\n#defense = SpatialSmoothing(window_size = 4)\ndefense = TotalVarMin()\n\n# Running the defense on adversarial images\ntest_images_pgd_cleaned_squeeze = defense(test_images_pgd_sqnet)[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-08T15:54:13.906502Z","iopub.execute_input":"2022-07-08T15:54:13.90685Z","iopub.status.idle":"2022-07-08T16:06:33.650668Z","shell.execute_reply.started":"2022-07-08T15:54:13.906822Z","shell.execute_reply":"2022-07-08T16:06:33.649513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import GaussianAugmentation\nfrom art.defences.preprocessor import LabelSmoothing\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:10:56.481624Z","iopub.execute_input":"2022-07-08T16:10:56.481985Z","iopub.status.idle":"2022-07-08T16:10:56.488441Z","shell.execute_reply.started":"2022-07-08T16:10:56.481956Z","shell.execute_reply":"2022-07-08T16:10:56.487154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defense2 = SpatialSmoothing()\ntest_images_pgd_cleaner_squeeze = defense2(test_images_pgd_cleaned_squeeze)[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:10:58.668954Z","iopub.execute_input":"2022-07-08T16:10:58.669421Z","iopub.status.idle":"2022-07-08T16:11:04.221642Z","shell.execute_reply.started":"2022-07-08T16:10:58.669392Z","shell.execute_reply":"2022-07-08T16:11:04.220269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defense3 = GaussianAugmentation(apply_predict = True, ratio= 2, clip_values= (0,1))\ntest_images_pgd_cleanest_squeeze = defense3(test_images_pgd_cleaner_squeeze)[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:11:19.595473Z","iopub.execute_input":"2022-07-08T16:11:19.595835Z","iopub.status.idle":"2022-07-08T16:11:28.26493Z","shell.execute_reply.started":"2022-07-08T16:11:19.595806Z","shell.execute_reply":"2022-07-08T16:11:28.263754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import JpegCompression\ndefense4 = JpegCompression(clip_values=(0,1), apply_predict = True)\ntest_images_pgd_cleanestest_squeeze = defense4(test_images_pgd_cleanest_squeeze)[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:11:29.808763Z","iopub.execute_input":"2022-07-08T16:11:29.811406Z","iopub.status.idle":"2022-07-08T16:13:20.489433Z","shell.execute_reply.started":"2022-07-08T16:11:29.811376Z","shell.execute_reply":"2022-07-08T16:13:20.488142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = classy.predict(x_tests)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"Clean accuracy:\", accuracy)\n\n\n\npredictions = classy.predict(test_images_pgd_sqnet)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"Adversarial accuracy:\", accuracy)\n\n\npredictions = classy.predict(test_images_pgd_cleaned_squeeze)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 1 Adversarial Defense accuracy:\", accuracy)\n\npredictions = classy.predict(test_images_pgd_cleaner_squeeze)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 2 Adversarial Defenses accuracy:\", accuracy)\n\npredictions = classy.predict(test_images_pgd_cleanest_squeeze)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 3 Adversarial Defenses accuracy:\", accuracy)\npredictions = classy.predict(test_images_pgd_cleanestest_squeeze)\n#print(predictions)\n#print(y_tests)\ncounter = 0\nfor x in range(479):\n    if np.argmax(predictions[x], axis=0) == np.argmax(y_tests[x], axis=0):\n        #print(x)\n        #print(np.argmax(predictions[x], axis=0))\n        #print(np.argmax(y_tests[x], axis=0))\n        counter+=1\naccuracy = counter / len(y_tests)\nprint(\"With 3 Adversarial Defenses accuracy:\", accuracy)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T16:13:28.622873Z","iopub.execute_input":"2022-07-08T16:13:28.623306Z","iopub.status.idle":"2022-07-08T16:13:33.876377Z","shell.execute_reply.started":"2022-07-08T16:13:28.623276Z","shell.execute_reply":"2022-07-08T16:13:33.874954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef show_prediction(img, label, pred, K=5, adv_img=None, noise=None):\n\n    if isinstance(img, torch.Tensor):\n        # Tensor image to numpy\n        img = img.cpu().permute(1, 2, 0).numpy()\n       # img = (img * NORM_STD[None,None]) + NORM_MEAN[None,None]\n        img = np.clip(img, a_min=0.0, a_max=1.0)\n        label = label.item()\n\n    # Plot on the left the image with the true label as title.\n    # On the right, have a horizontal bar plot with the top k predictions including probabilities\n    if noise is None or adv_img is None:\n        fig, ax = plt.subplots(1, 2, figsize=(10,2), gridspec_kw={'width_ratios': [1, 1]})\n    else:\n        fig, ax = plt.subplots(1, 5, figsize=(12,2), gridspec_kw={'width_ratios': [1, 1, 1, 1, 2]})\n\n    ax[0].imshow(img)\n    ax[0].set_title(class_names[label])\n    ax[0].axis('off')\n\n    if adv_img is not None and noise is not None:\n        # Visualize adversarial images\n        adv_img = adv_img.cpu().permute(1, 2, 0).numpy()\n       # adv_img = (adv_img * NORM_STD[None,None]) + NORM_MEAN[None,None]\n        adv_img = np.clip(adv_img, a_min=0.0, a_max=1.0)\n        ax[1].imshow(adv_img)\n        ax[1].set_title('Adversarial')\n        ax[1].axis('off')\n        # Visualize noise\n        noise = noise.cpu().permute(1, 2, 0).numpy()\n        noise = noise * 0.5 + 0.5 # Scale between 0 to 1\n        ax[2].imshow(noise)\n        ax[2].set_title('Noise')\n        ax[2].axis('off')\n        # buffer\n        ax[3].axis('off')\n\n    if abs(pred.sum().item() - 1.0) > 1e-4:\n        pred = torch.softmax(pred, dim=-1)\n    topk_vals, topk_idx = pred.topk(K, dim=-1)\n    topk_vals, topk_idx = topk_vals.cpu().numpy(), topk_idx.cpu().numpy()\n    ax[-1].barh(np.arange(K), topk_vals*100.0, align='center', color=[\"C0\" if topk_idx[i]!=label else \"C2\" for i in range(K)])\n    ax[-1].set_yticks(np.arange(K))\n    ax[-1].set_yticklabels([class_names[c] for c in topk_idx])\n    ax[-1].invert_yaxis()\n    ax[-1].set_xlabel('Confidence')\n    ax[-1].set_title('Predictions')\n\n    plt.show()\n    plt.close()\n\n\n\ndef fast_gradient_sign_method(model, imgs, labels, epsilon=0.3):\n    # Determine prediction of the model\n    inp_imgs = imgs.clone().requires_grad_()\n    preds = model(inp_imgs.to(device))\n    #preds = F.log_softmax(preds, dim=-1)\n    # Calculate loss by NLL\n    loss = -torch.gather(preds, 1, labels.to(device).unsqueeze(dim=-1))\n    loss.sum().backward()\n    # Update image to adversarial example as written above\n    noise_grad = torch.sign(inp_imgs.grad.to(imgs.device))\n    fake_imgs = imgs + epsilon * noise_grad\n    fake_imgs.detach_()\n    return fake_imgs, noise_grad","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:17:01.259264Z","iopub.execute_input":"2022-07-13T20:17:01.259934Z","iopub.status.idle":"2022-07-13T20:17:01.306843Z","shell.execute_reply.started":"2022-07-13T20:17:01.259839Z","shell.execute_reply":"2022-07-13T20:17:01.305861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, labels = next(iter(dataloaders_dict['val']))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:18:44.011293Z","iopub.execute_input":"2022-07-13T20:18:44.011861Z","iopub.status.idle":"2022-07-13T20:18:45.370219Z","shell.execute_reply.started":"2022-07-13T20:18:44.011816Z","shell.execute_reply":"2022-07-13T20:18:45.369033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" adv_imgs, noise_grad = fast_gradient_sign_method(model, img, labels, epsilon=.3)\nwith torch.no_grad():\n    adv_preds = model(adv_imgs.to(device))\n\nfor i in range(1,64,1):\n    show_prediction(img[i], labels[i], adv_preds[i], adv_img=adv_imgs[i], noise=noise_grad[i])","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:20:12.917841Z","iopub.execute_input":"2022-07-13T20:20:12.918319Z","iopub.status.idle":"2022-07-13T20:20:30.095397Z","shell.execute_reply.started":"2022-07-13T20:20:12.918278Z","shell.execute_reply":"2022-07-13T20:20:30.093799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install adversarial-robustness-toolbox","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:22:46.481126Z","iopub.execute_input":"2022-07-13T20:22:46.481579Z","iopub.status.idle":"2022-07-13T20:23:02.102337Z","shell.execute_reply.started":"2022-07-13T20:22:46.481539Z","shell.execute_reply":"2022-07-13T20:23:02.100881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import SpatialSmoothing\nfrom art.defences.preprocessor import TotalVarMin\nfrom art.defences.preprocessor import FeatureSqueezing\nfrom art.defences.preprocessor import ThermometerEncoding\n\n#defense = SpatialSmoothing(window_size = 4)\ndefense = TotalVarMin(clip_values = (0,1))\n\n# Running the defense on adversarial images\nclean = defense(adv_imgs.numpy())[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-13T20:52:56.264356Z","iopub.execute_input":"2022-07-13T20:52:56.264795Z","iopub.status.idle":"2022-07-13T20:53:42.012686Z","shell.execute_reply.started":"2022-07-13T20:52:56.264761Z","shell.execute_reply":"2022-07-13T20:53:42.011554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adv_imgs.dtype","metadata":{"execution":{"iopub.status.busy":"2022-07-13T21:02:07.143571Z","iopub.execute_input":"2022-07-13T21:02:07.143997Z","iopub.status.idle":"2022-07-13T21:02:07.151786Z","shell.execute_reply.started":"2022-07-13T21:02:07.143962Z","shell.execute_reply":"2022-07-13T21:02:07.150508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.from_numpy(clean).dtype","metadata":{"execution":{"iopub.status.busy":"2022-07-13T21:02:09.264874Z","iopub.execute_input":"2022-07-13T21:02:09.265997Z","iopub.status.idle":"2022-07-13T21:02:09.273472Z","shell.execute_reply.started":"2022-07-13T21:02:09.265954Z","shell.execute_reply":"2022-07-13T21:02:09.272135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    \n    adv_preds = model(torch.from_numpy(clean))\n\nfor i in range(1,64,1):\n    show_prediction(img[i], labels[i], adv_preds[i], adv_img=torch.from_numpy(clean[i]), noise=noise_grad[i])","metadata":{"execution":{"iopub.status.busy":"2022-07-13T21:02:12.205766Z","iopub.execute_input":"2022-07-13T21:02:12.206863Z","iopub.status.idle":"2022-07-13T21:02:24.280389Z","shell.execute_reply.started":"2022-07-13T21:02:12.206823Z","shell.execute_reply":"2022-07-13T21:02:24.278800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.max(adv_preds, 1)","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:01:16.069254Z","iopub.execute_input":"2022-07-13T22:01:16.069634Z","iopub.status.idle":"2022-07-13T22:01:16.080877Z","shell.execute_reply.started":"2022-07-13T22:01:16.069601Z","shell.execute_reply":"2022-07-13T22:01:16.077750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:01:28.746946Z","iopub.execute_input":"2022-07-13T22:01:28.747349Z","iopub.status.idle":"2022-07-13T22:01:28.754476Z","shell.execute_reply.started":"2022-07-13T22:01:28.747318Z","shell.execute_reply":"2022-07-13T22:01:28.753541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    \n    adv_preds = model(img)\n\nfor i in range(1,64,1):\n    show_prediction(img[i], labels[i], adv_preds[i], adv_img=img[i], noise=noise_grad[i])","metadata":{"execution":{"iopub.status.busy":"2022-07-13T22:10:40.287720Z","iopub.execute_input":"2022-07-13T22:10:40.288132Z","iopub.status.idle":"2022-07-13T22:10:53.935039Z","shell.execute_reply.started":"2022-07-13T22:10:40.288102Z","shell.execute_reply":"2022-07-13T22:10:53.933236Z"},"trusted":true},"execution_count":null,"outputs":[]}]}